---
title: "320-Final"
author: "Jinghan Chen"
date:  "`r format(Sys.time(), '%B %d, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(dplyr)
library(reshape2)
library(ggthemes)
```

```{r}
library(readr)
vgsales <- read_csv("Video_Games_Sales_as_at_22_Dec_2016.csv")
# world gdp data extracted from worldbank 
gdp <- read_csv('worldgdp.csv', skip = 4, na = c("", "NA"))
pop <- read_csv('worldpop.csv', skip = 4, na = c("", "NA"))
head(vgsales)
```


```{r}
# 6875 non-empty values in dataset, omit any rows with empty values
vgsales[vgsales == 'N/A'] = NA
vgsales1 <- na.omit(vgsales)
vgsales1 <- vgsales1[vgsales1$Year_of_Release != 2020,]
vgsales1 <- vgsales1[,-16]
vgsales1 <- vgsales1[,-15]
vgsales1 <- vgsales1[,-12]
names(vgsales1)[names(vgsales1) == "Year_of_Release"] <- "Year"
head(vgsales1)

```

```{r}
# clean world gdp data
countrylist = c('Japan', 'United States', 'European Union')
gdp <- gdp %>%
  select('Country Name', '1980':'2018')
gdp = gdp[gdp$`Country Name` %in% countrylist,]
gdp = melt(gdp, id.vars = 'Country Name', var = 'Year')
gdp$`Country Name`[gdp$`Country Name` == 'Japan'] = 'JP'
gdp$`Country Name`[gdp$`Country Name` == 'United States'] = 'NA'
gdp$`Country Name`[gdp$`Country Name` == 'European Union'] = 'EU'
names(gdp)[names(gdp) == "Country Name"] <- "Region"
```

```{r}
# clean world population data
pop <- pop %>%
  select('Country Name', '1980':'2018')
pop = pop[pop$`Country Name` %in% countrylist,]
pop = melt(pop, id.vars = 'Country Name', var = 'Year')
pop$`Country Name`[pop$`Country Name` == 'Japan'] = 'JP'
pop$`Country Name`[pop$`Country Name` == 'United States'] = 'NA'
pop$`Country Name`[pop$`Country Name` == 'European Union'] = 'EU'
names(pop)[names(pop) == "Country Name"] <- "Region"
```

```{r}
# merge sales data with gdp and sales 
temp <- vgsales1[,c(1,6:8)]
temp <- melt(temp, id.vars = 'Name', var = 'Region')
temp$Region <- gsub("_.*","",temp$Region)
merged_vgsales <- vgsales1 %>%
  select(1:5,11:13) %>%
  left_join(temp, by = 'Name') %>%
  rename(sales = value) %>%
  left_join(gdp, by = c('Region','Year')) %>%
  rename(gdp = value) %>%
  left_join(pop, by = c('Region','Year')) %>%
  rename(pop = value)
merged_vgsales2 <- merged_vgsales %>%
  transform(sales = sales * 1000000) %>% 
  mutate(sales_per_capita = sales/pop) 
  
merged_vgsales2 <- merged_vgsales2[,-1]
merged_vgsales2 <- merged_vgsales2[,-12]
merged_vgsales2$Platform = factor(merged_vgsales2$Platform)
merged_vgsales2$Genre = factor(merged_vgsales2$Genre)
merged_vgsales2$Publisher = factor(merged_vgsales2$Publisher)
merged_vgsales2$Region = factor(merged_vgsales2$Region)
merged_vgsales2$Year = as.numeric(merged_vgsales2$Year)
merged_vgsales2$User_Score = as.numeric(merged_vgsales2$User_Score)
merged_vgsales2
```


```{r}
library(ISLR)
library(randomForest)
library(gbm)
library(dplyr)
smp_siz = floor(0.75*nrow(merged_vgsales2))  # creates a value for dividing the data into train and test. In this case the value is defined as 75% of the number of rows in the dataset
smp_siz
set.seed(123)   # set seed to ensure you always have same random numbers generated
train_ind = sample(seq_len(nrow(merged_vgsales2)),size = smp_siz)  
# Randomly identifies therows equal to sample size ( defined in previous instruction) from  all the rows of Smarket dataset and stores the row number in train_ind
train =merged_vgsales2[train_ind,] 
#creates the training dataset with row numbers stored in train_ind
test=merged_vgsales2[-train_ind,]
n=dim(train)[1]
n_fold<-5
folds_i <- sample(rep(1:n_fold, length.out = n))
OUT.boo=NULL
TRUTHboo=NULL
OUTPUTboo=NULL
set.seed(3)
for (k in 1:n_fold) 
{
  test.ID <- which(folds_i == k)
  train_set <- train[-test.ID, ]
  test_set <- train[test.ID, ]
  
  boo=gbm(sales~.,data=train_set,distribution = "gaussian", n.trees=100, shrinkage=0.001,interaction.depth = 2)
  predicted_boo=predict(boo,test_set,n.trees = 100, type = 'response')
  mse=mean((predicted_boo-train$sales)^2) 
  OUT.boo=c(OUT.boo, mse)
}
```

```{r}
mean(OUT.boo)
sd(OUT.boo) #standard error:
```

```{r}
boo=gbm(sales~.,data=train,distribution = "gaussian", n.trees=100, shrinkage=0.001,interaction.depth = 2)
predicted_boo=predict(boo,test,n.trees = 100, type = 'response')
mse=mean((predicted_boo-train$sales)^2)
mse
```

```{r}
summary(boo,order = TRUE)
```


```{r}
# correlation matrix
# corr matrix for categorical vars 
vgsales_final = merged_vgsales2
head(vgsales_final)

vgsales_final[,1:11] <- lapply(vgsales_final[,1:11],as.integer)

corrplot(cor(vgsales_final), type = "upper", order = "hclust", tl.col = "black")
```

```{r}
## baseline 
mod1 <- lm(sales ~., data = vgsales_final)
summary(mod1)
```

```{r}
# Ridge Regression
lambdas <- 10^seq(5, -2, by = -.1)

Mx<- model.matrix(sales ~ .^2, data=vgsales_final)[,-1] # matrix for predictors
My<- vgsales_final$sales # vector for y

# fit ridge model over lambda choices, 5-fold validation
cv_glm_fit  <- cv.glmnet(Mx, My, alpha = 0, lambda = lambdas, nfolds = 5) 
plot(cv_glm_fit)

# grab optimal lambda = 0.01
opt_lambda <- cv_glm_fit$lambda.min

glm_fit <- cv_glm_fit$glmnet.fit
summary(glm_fit)
# grab coefficient outputs for optimal lambda
coef(glm_fit)[,which(glm_fit$lambda == opt_lambda)]

# predict using fitted model
y_predicted<-predict(glm_fit, s = opt_lambda, newx = Mx)

# Sum of Squares Total and Error
sst <- sum((My - mean(My))^2)
sse <- sum((y_predicted - My)^2)
sst
sse

# R squared
rsq <- 1 - sse / sst
rsq

```

```{r}
library(tidyverse)
library(ggplot2)
library(modelr)
library(purrr)
library(broom)
library(glmnet)
complete = merged_vgsales2[complete.cases(merged_vgsales2), ]
DATA=complete[sample(nrow(complete), 750), ]
DATA2=DATA[,c("Platform","Year","Genre","Publisher","Critic_Score","User_Score","User_Count","Region","sales","gdp","pop")]
head(DATA2)
y=DATA2$sales
X=model_matrix(DATA2, sales~.*.)[,-1]
var.names=names(X)
dim(X)
dim(y)

set.seed(216)
cvmod.0=cv.glmnet(y=y,x=as.matrix(X),alpha=0)
set.seed(216)
cvmod.25=cv.glmnet(y=y,x=as.matrix(X),alpha=0.25)
set.seed(216)
cvmod.5=cv.glmnet(y=y,x=as.matrix(X),alpha=0.5)
set.seed(216)
cvmod.75=cv.glmnet(y=y,x=as.matrix(X),alpha=0.75)
set.seed(216)
cvmod.1=cv.glmnet(y=y,x=as.matrix(X),alpha=1)
CV.0.ERROR=cvmod.0$cvm[which(cvmod.0$lambda==cvmod.0$lambda.1se)]
CV.25.ERROR=cvmod.25$cvm[which(cvmod.25$lambda==cvmod.25$lambda.1se)]
CV.5.ERROR=cvmod.5$cvm[which(cvmod.5$lambda==cvmod.5$lambda.1se)]
CV.75.ERROR=cvmod.75$cvm[which(cvmod.75$lambda==cvmod.75$lambda.1se)]
CV.1.ERROR=cvmod.1$cvm[which(cvmod.1$lambda==cvmod.1$lambda.1se)]
MOD.RESULT=tibble(alpha=c(0,0.25,0.5,0.75,1),
                  lambda=c(cvmod.0$lambda.1se,cvmod.25$lambda.1se,
                           cvmod.5$lambda.1se,cvmod.75$lambda.1se,
                           cvmod.1$lambda.1se),
                  CV.Error=c(CV.0.ERROR,CV.25.ERROR,CV.5.ERROR,
                             CV.75.ERROR,CV.1.ERROR))
print(MOD.RESULT)

best.alpha=MOD.RESULT$alpha[which.min(MOD.RESULT$CV.Error)]
best.lambda=MOD.RESULT$lambda[which.min(MOD.RESULT$CV.Error)]
best.mod=glmnet(y=y,x=as.matrix(X),nlambda=1,lambda=best.lambda,alpha=best.alpha)
best.coef=as.tibble(as.matrix(coef(best.mod)))
best.coef2=best.coef %>% 
              mutate(Parameter=c("Int",var.names)) %>%
              rename(Estimate=s0) %>%
              select(Parameter,Estimate)
nonzero.best.coef=best.coef2 %>%
                    filter(Estimate!=0)
print(nonzero.best.coef,n=1e3)
DATA2$GS.hat=predict(best.mod,newx=as.matrix(X))

ggplot(DATA2) +
  geom_point(aes(x=sales,y=GS.hat),color="lightskyblue2") +
  geom_abline(a=0,b=1,linetype="dashed") +
  theme_minimal() +
  ylab("Predicted Global Sales") +
  xlab("Actual Global Sales")
ggplot(DATA2) +
  geom_histogram(aes(x=sales-GS.hat),fill="lightskyblue2") +
  theme_minimal() +
  xlab("Residuals") +
  ylab("Frequency")
```


